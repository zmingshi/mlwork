{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# /usr/bin/python\n",
    "# -*- encoding:utf-8 -*-\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    acc_rate = 100 * float(acc.sum()) / a.size\n",
    "    print '%s正确率：%.3f%%' % (tip, acc_rate)\n",
    "    return acc_rate\n",
    "\n",
    "\n",
    "def load_data(file_name, is_train):\n",
    "    data = pd.read_csv(file_name)  # 数据文件路径\n",
    "    # print 'data.describe() = \\n', data.describe()\n",
    "\n",
    "    # 性别\n",
    "    data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "    # 补齐船票价格缺失值\n",
    "    if len(data.Fare[data.Fare.isnull()]) > 0:\n",
    "        fare = np.zeros(3)\n",
    "        for f in range(0, 3):\n",
    "            fare[f] = data[data.Pclass == f + 1]['Fare'].dropna().median()\n",
    "        for f in range(0, 3):  # loop 0 to 2\n",
    "            data.loc[(data.Fare.isnull()) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n",
    "\n",
    "    # 年龄：使用均值代替缺失值\n",
    "    # mean_age = data['Age'].dropna().mean()\n",
    "    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "    if is_train:\n",
    "        # 年龄：使用随机森林预测年龄缺失值\n",
    "        print '随机森林预测缺失年龄：--start--'\n",
    "        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]  # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print age_exist\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄：--over--'\n",
    "    else:\n",
    "        print '随机森林预测缺失年龄2：--start--'\n",
    "        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]  # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print age_exist\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print '随机森林预测缺失年龄2：--over--'\n",
    "\n",
    "    # 起始城市\n",
    "    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # 保留缺失出发城市\n",
    "    # data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2, 'U': 0}).astype(int)\n",
    "    # print data['Embarked']\n",
    "    embarked_data = pd.get_dummies(data.Embarked)\n",
    "    print embarked_data\n",
    "    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "    data = pd.concat([data, embarked_data], axis=1)\n",
    "    print data.describe()\n",
    "    data.to_csv('New_Data.csv')\n",
    "\n",
    "    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    # x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    y = None\n",
    "    if 'Survived' in data:\n",
    "        y = data['Survived']\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 思考：这样做，其实发生了什么？\n",
    "    x = np.tile(x, (5, 1))\n",
    "    y = np.tile(y, (5,))\n",
    "    if is_train:\n",
    "        return x, y\n",
    "    return x, data['PassengerId']\n",
    "\n",
    "\n",
    "def write_result(c, c_type):\n",
    "    file_name = '../dataset/Titanic.test.csv'\n",
    "    x, passenger_id = load_data(file_name, False)\n",
    "\n",
    "    if type == 3:\n",
    "        x = xgb.DMatrix(x)\n",
    "    y = c.predict(x)\n",
    "    y[y > 0.5] = 1\n",
    "    y[~(y > 0.5)] = 0\n",
    "\n",
    "    predictions_file = open(\"Prediction_%d.csv\" % c_type, \"wb\")\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "    open_file_object.writerows(zip(passenger_id, y))\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林预测缺失年龄：--start--\n",
      "随机森林预测缺失年龄：--over--\n",
      "     C  Q  S  U\n",
      "0    0  0  1  0\n",
      "1    1  0  0  0\n",
      "2    0  0  1  0\n",
      "3    0  0  1  0\n",
      "4    0  0  1  0\n",
      "5    0  1  0  0\n",
      "6    0  0  1  0\n",
      "7    0  0  1  0\n",
      "8    0  0  1  0\n",
      "9    1  0  0  0\n",
      "10   0  0  1  0\n",
      "11   0  0  1  0\n",
      "12   0  0  1  0\n",
      "13   0  0  1  0\n",
      "14   0  0  1  0\n",
      "15   0  0  1  0\n",
      "16   0  1  0  0\n",
      "17   0  0  1  0\n",
      "18   0  0  1  0\n",
      "19   1  0  0  0\n",
      "20   0  0  1  0\n",
      "21   0  0  1  0\n",
      "22   0  1  0  0\n",
      "23   0  0  1  0\n",
      "24   0  0  1  0\n",
      "25   0  0  1  0\n",
      "26   1  0  0  0\n",
      "27   0  0  1  0\n",
      "28   0  1  0  0\n",
      "29   0  0  1  0\n",
      "..  .. .. .. ..\n",
      "861  0  0  1  0\n",
      "862  0  0  1  0\n",
      "863  0  0  1  0\n",
      "864  0  0  1  0\n",
      "865  0  0  1  0\n",
      "866  1  0  0  0\n",
      "867  0  0  1  0\n",
      "868  0  0  1  0\n",
      "869  0  0  1  0\n",
      "870  0  0  1  0\n",
      "871  0  0  1  0\n",
      "872  0  0  1  0\n",
      "873  0  0  1  0\n",
      "874  1  0  0  0\n",
      "875  1  0  0  0\n",
      "876  0  0  1  0\n",
      "877  0  0  1  0\n",
      "878  0  0  1  0\n",
      "879  1  0  0  0\n",
      "880  0  0  1  0\n",
      "881  0  0  1  0\n",
      "882  0  0  1  0\n",
      "883  0  0  1  0\n",
      "884  0  0  1  0\n",
      "885  0  1  0  0\n",
      "886  0  0  1  0\n",
      "887  0  0  1  0\n",
      "888  0  0  1  0\n",
      "889  1  0  0  0\n",
      "890  0  1  0  0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.655493   \n",
      "std     257.353842    0.486592    0.836071    0.477990   13.743316   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   21.000000   \n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   37.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.523008    0.381594   32.204208    0.188552    0.086420    0.722783   \n",
      "std      1.102743    0.806057   49.693429    0.391372    0.281141    0.447876   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    7.910400    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000   14.454200    0.000000    0.000000    1.000000   \n",
      "75%      1.000000    0.000000   31.000000    0.000000    0.000000    1.000000   \n",
      "max      8.000000    6.000000  512.329200    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Embarked_U  \n",
      "count  891.000000  \n",
      "mean     0.002245  \n",
      "std      0.047351  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      0.000000  \n",
      "max      1.000000  \n",
      "Logistic回归：0.805%\n"
     ]
    }
   ],
   "source": [
    "x, y = load_data('../dataset/Titanic.train.csv', True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "#\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(x_train, y_train)\n",
    "y_hat = lr.predict(x_test)\n",
    "lr_acc = accuracy_score(y_test, y_hat)\n",
    "# write_result(lr, 1)\n",
    "print 'Logistic回归：%.3f%%' % lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林：0.983%\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train, y_train)\n",
    "y_hat = rfc.predict(x_test)\n",
    "rfc_acc = accuracy_score(y_test, y_hat)\n",
    "# write_result(rfc, 2)\n",
    "print '随机森林：%.3f%%' % rfc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.151706\ttrain-error:0.129003\n",
      "[1]\teval-error:0.124776\ttrain-error:0.108051\n",
      "[2]\teval-error:0.118492\ttrain-error:0.093685\n",
      "[3]\teval-error:0.091562\ttrain-error:0.068243\n",
      "[4]\teval-error:0.085278\ttrain-error:0.058366\n",
      "[5]\teval-error:0.081688\ttrain-error:0.055073\n",
      "[6]\teval-error:0.073609\ttrain-error:0.048788\n",
      "[7]\teval-error:0.06912\ttrain-error:0.045795\n",
      "[8]\teval-error:0.06553\ttrain-error:0.042502\n",
      "[9]\teval-error:0.06912\ttrain-error:0.042802\n",
      "[10]\teval-error:0.05386\ttrain-error:0.028435\n",
      "[11]\teval-error:0.058348\ttrain-error:0.028435\n",
      "[12]\teval-error:0.050269\ttrain-error:0.026639\n",
      "[13]\teval-error:0.046679\ttrain-error:0.023346\n",
      "[14]\teval-error:0.045781\ttrain-error:0.023646\n",
      "[15]\teval-error:0.047576\ttrain-error:0.024544\n",
      "[16]\teval-error:0.047576\ttrain-error:0.024544\n",
      "[17]\teval-error:0.037702\ttrain-error:0.018857\n",
      "[18]\teval-error:0.032316\ttrain-error:0.016163\n",
      "[19]\teval-error:0.030521\ttrain-error:0.015265\n",
      "[20]\teval-error:0.030521\ttrain-error:0.015265\n",
      "[21]\teval-error:0.025135\ttrain-error:0.012571\n",
      "[22]\teval-error:0.029623\ttrain-error:0.014068\n",
      "[23]\teval-error:0.022442\ttrain-error:0.011972\n",
      "[24]\teval-error:0.021544\ttrain-error:0.012272\n",
      "[25]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[26]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[27]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[28]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[29]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[30]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[31]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[32]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[33]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[34]\teval-error:0.019749\ttrain-error:0.011374\n",
      "[35]\teval-error:0.018851\ttrain-error:0.010177\n",
      "[36]\teval-error:0.017953\ttrain-error:0.010476\n",
      "[37]\teval-error:0.018851\ttrain-error:0.010177\n",
      "[38]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[39]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[40]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[41]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[42]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[43]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[44]\teval-error:0.016158\ttrain-error:0.009578\n",
      "[45]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[46]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[47]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[48]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[49]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[50]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[51]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[52]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[53]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[54]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[55]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[56]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[57]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[58]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[59]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[60]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[61]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[62]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[63]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[64]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[65]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[66]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[67]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[68]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[69]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[70]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[71]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[72]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[73]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[74]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[75]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[76]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[77]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[78]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[79]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[80]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[81]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[82]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[83]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[84]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[85]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[86]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[87]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[88]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[89]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[90]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[91]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[92]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[93]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[94]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[95]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[96]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[97]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[98]\teval-error:0.017056\ttrain-error:0.009279\n",
      "[99]\teval-error:0.017056\ttrain-error:0.009279\n",
      "XGBoost：0.983%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 6, 'eta': 0.8, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "# 'subsample': 1, 'alpha': 0, 'lambda': 0, 'min_child_weight': 1}\n",
    "bst = xgb.train(param, data_train, num_boost_round=100, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "# write_result(bst, 3)\n",
    "y_hat[y_hat > 0.5] = 1\n",
    "y_hat[~(y_hat > 0.5)] = 0\n",
    "xgb_acc = accuracy_score(y_test, y_hat)\n",
    "\n",
    "print 'XGBoost：%.3f%%' % xgb_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
