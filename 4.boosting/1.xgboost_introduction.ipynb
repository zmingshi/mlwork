{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# /usr/bin/python\n",
    "# -*- encoding:utf-8 -*-\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# 1、xgBoost的基本使用\n",
    "# 2、自定义损失函数的梯度和二阶导\n",
    "# 3、binary:logistic/logitraw\n",
    "\n",
    "# 定义f: theta * x\n",
    "def log_reg(y_hat, y):\n",
    "    p = 1.0 / (1.0 + np.exp(-y_hat))\n",
    "    g = p - y.get_label()\n",
    "    h = p * (1.0 - p)\n",
    "    return g, h\n",
    "\n",
    "\n",
    "def error_rate(y_hat, y):\n",
    "    return 'error', float(sum(y.get_label() != (y_hat > 0.5))) / len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x7fdb93817d50>\n",
      "<class 'xgboost.core.DMatrix'>\n",
      "[0]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[1]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[2]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[3]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[4]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[5]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[6]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[  6.09937888e-06   9.84727502e-01   6.09937888e-06 ...,   9.99932647e-01\n",
      "   4.45600620e-07   9.99932647e-01]\n",
      "[ 0.  1.  0. ...,  1.  0.  1.]\n",
      "样本总数：\t1611\n",
      "错误数目：\t   4\n",
      "错误率：\t0.24829%\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data_train = xgb.DMatrix('../dataset/agaricus_train.txt')\n",
    "data_test = xgb.DMatrix('../dataset/agaricus_test.txt')\n",
    "print data_train\n",
    "print type(data_train)\n",
    "\n",
    "# 设置参数\n",
    "param = {'max_depth': 3, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}  # logitraw\n",
    "# param = {'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'reg:logistic'}\n",
    "watchlist = [(data_test, 'eval'), (data_train, 'train')]\n",
    "n_round = 7\n",
    "# bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist)\n",
    "bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist, obj=log_reg, feval=error_rate)\n",
    "\n",
    "# 计算错误率\n",
    "y_hat = bst.predict(data_test)\n",
    "y = data_test.get_label()\n",
    "print y_hat\n",
    "print y\n",
    "error = sum(y != (y_hat > 0.5))\n",
    "error_rate = float(error) / len(y_hat)\n",
    "print '样本总数：\\t', len(y_hat)\n",
    "print '错误数目：\\t%4d' % error\n",
    "print '错误率：\\t%.5f%%' % (100 * error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.04\ttrain-merror:0.04\n",
      "[1]\teval-merror:0.04\ttrain-merror:0.04\n",
      "[2]\teval-merror:0.02\ttrain-merror:0.02\n",
      "[3]\teval-merror:0.02\ttrain-merror:0.02\n",
      "[4]\teval-merror:0.02\ttrain-merror:0.02\n",
      "[5]\teval-merror:0.02\ttrain-merror:0.02\n",
      "正确率:\t0.98\n",
      "END.....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split  # cross_validation\n",
    "def iris_type(s):\n",
    "    it = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "    return it[s]\n",
    "\n",
    "\n",
    "path = '../dataset/iris.data'  # 数据文件路径\n",
    "data = np.loadtxt(path, dtype=float, delimiter=',', converters={4: iris_type})\n",
    "data = pd.read_csv(path, header=None)\n",
    "x, y = data[range(4)], data[4]\n",
    "y = pd.Categorical(y).codes\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=50)\n",
    "\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 2, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "bst = xgb.train(param, data_train, num_boost_round=6, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "result = y_test.reshape(1, -1) == y_hat\n",
    "print '正确率:\\t', float(np.sum(result)) / len(y_hat)\n",
    "print 'END.....\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    y = []\n",
    "    row = []\n",
    "    col = []\n",
    "    values = []\n",
    "    r = 0       # 首行\n",
    "    for d in open(path):\n",
    "        d = d.strip().split()      # 以空格分开\n",
    "        y.append(int(d[0]))\n",
    "        d = d[1:]\n",
    "        for c in d:\n",
    "            key, value = c.split(':')\n",
    "            row.append(r)\n",
    "            col.append(int(key))\n",
    "            values.append(float(value))\n",
    "        r += 1\n",
    "    x = scipy.sparse.csr_matrix((values, (row, col))).toarray()\n",
    "    y = np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic回归正确率： 1.0\n",
      "[0]\teval-merror:0.035687\ttrain-merror:0.040696\n",
      "[1]\teval-merror:0.007291\ttrain-merror:0.009982\n",
      "[2]\teval-merror:0.000767\ttrain-merror:0.000512\n",
      "[3]\teval-merror:0.000767\ttrain-merror:0.000512\n",
      "XGBoost正确率： 0.999232540292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "x, y = read_data('../dataset/agaricus_train.txt')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, train_size=0.6)\n",
    "\n",
    "# Logistic回归\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(x_train, y_train.ravel())\n",
    "y_hat = lr.predict(x_test)\n",
    "print 'Logistic回归正确率：', accuracy_score(y_test, y_hat)\n",
    "\n",
    "# XGBoost\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 3, 'eta': 1, 'silent': 0, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "bst = xgb.train(param, data_train, num_boost_round=4, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "print 'XGBoost正确率：', accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic回归正确率： 0.943820224719\n",
      "[0]\teval-merror:0.011236\ttrain-merror:0\n",
      "[1]\teval-merror:0\ttrain-merror:0\n",
      "XGBoost正确率： 1.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  # cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "data = np.loadtxt('../dataset/wine.data', dtype=float, delimiter=',')\n",
    "y, x = np.split(data, (1,), axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.5)\n",
    "\n",
    "# Logistic回归\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "lr.fit(x_train, y_train.ravel())\n",
    "y_hat = lr.predict(x_test)\n",
    "print 'Logistic回归正确率：', accuracy_score(y_test, y_hat)\n",
    "\n",
    "# XGBoost\n",
    "y_train[y_train == 3] = 0\n",
    "y_test[y_test == 3] = 0\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "params = {'max_depth': 3, 'eta': 1, 'silent': 0, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "bst = xgb.train(params, data_train, num_boost_round=2, evals=watch_list)\n",
    "y_hat = bst.predict(data_test)\n",
    "print 'XGBoost正确率：', accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
