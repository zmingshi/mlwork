{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "//二分法求解\n",
    "double sqrt(double A) {\n",
    "    double a = 0, b = A + 0.25, m;\n",
    "    int iter = 0;\n",
    "    while (true) {\n",
    "        m = a + (b-a)/2;\n",
    "        if ((m - a) < DBL_EPSILON || (b - m) < DBL_EPSILON) {\n",
    "            break;\n",
    "        }\n",
    "        iter++;\n",
    "        if ((a * a - A) * (m * m - A) < 0.0) {\n",
    "            b = m;\n",
    "        } else {\n",
    "            a = m;\n",
    "        }\n",
    "    }\n",
    "    printf(\"iter num: %d\\n\", iter);\n",
    "    return m;\n",
    "}\n",
    "\n",
    "//牛顿法求解\n",
    "double sqrt_newton(double A) {\n",
    "    double x0 = A + 0.25, x1;\n",
    "    int iter = 0;\n",
    "    while(true) {\n",
    "        x1 = (x0*x0 + A)/(2 * x0);\n",
    "        if(fabs(x0 - x1) < DBL_EPSILON) {\n",
    "            break;\n",
    "        }\n",
    "        iter++;\n",
    "        x0 = x1;\n",
    "    }\n",
    "\n",
    "    printf(\"iter num: %d\\n\", iter);\n",
    "    return x1;\n",
    "}\n",
    "//割线法求解\n",
    "double sqrt_line(double A) {\n",
    "    double x0 = 0, x1 = A + 0.25, x2;\n",
    "    double fx0 = x0*x0- A, fx1 = x1*x1-A;\n",
    "    int iter = 0;\n",
    "    while(true) {\n",
    "        x2 = x1 - fx1/(fx1-fx0)*(x1 - x0);\n",
    "        if(fabs(x2 - x1) < DBL_EPSILON) {\n",
    "            break;\n",
    "        }\n",
    "        iter++;\n",
    "        x0 = x1;\n",
    "        x1 = x2;\n",
    "        fx0 = fx1;\n",
    "        fx1 = x1*x1 - A;\n",
    "    }\n",
    "\n",
    "    printf(\"iter num: %d\\n\", iter);\n",
    "    return x2;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同的优化算法的区别就在于目标函数下降方向Dt的计算。下降方向是通过对目标函数在当前的W下求一阶倒数（梯度，Gradient）和求二阶导数（海森矩阵，Hessian Matrix）得到。常见的算法有梯度下降法、牛顿法、拟牛顿法。\n",
    "\n",
    "1.梯度下降法(Gradient Descent)\n",
    "\n",
    "梯度下降法直接采用目标函数在当前W的梯度的反方向作为下降方向：\n",
    "\n",
    "其中为目标函数的梯度，计算方法为：\n",
    "\n",
    "公式（2）\n",
    "\n",
    "2.牛顿法(Newton Methods)\n",
    "\n",
    "牛顿法是在当前W下，利用二次泰勒展开近似目标函数，然后利用该近似函数来求解目标函数的下降方向:。其中Bt为目标函数f(W)在Wt处的海森矩阵。这个搜索方向也称作牛顿方向。\n",
    "\n",
    "3.拟牛顿法(Quasi-Newton Methods)：\n",
    "\n",
    "拟牛顿法只要求每一步迭代中计算目标函数的梯度，通过拟合的方式找到一个近似的海森矩阵用于计算牛顿方向。最早的拟牛顿法是DFP（1959年由W. C. Davidon提出，并由R. Fletcher和M. J. D. Powell进行完善）。DFP继承了牛顿法收敛速度快的优点，并且避免了牛顿法中每次迭代都需要重新计算海森矩阵的问题，只需要利用梯度更新上一次迭代得到的海森矩阵，但缺点是每次迭代中都需要计算海森矩阵的逆，才能得到牛顿方向。\n",
    "\n",
    "BFGS是由C. G. Broyden, R. Fletcher, D. Goldfarb和D. F. Shanno各自独立发明的一种方法，只需要增量计算海森矩阵的逆Ht=Bt-1，避免了每次迭代中的矩阵求逆运算。BFGS中牛顿方向表示为：\n",
    "\n",
    "L-BFGS(Limited-memory BFGS)则是解决了BFGS中每次迭代后都需要保存N*N阶海森逆矩阵的问题，只需要保存每次迭代的两组向量和一组标量即可：\n",
    "\n",
    "在L-BFGS的第t次迭代中，只需要两步循环既可以增量计算牛顿方向：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
