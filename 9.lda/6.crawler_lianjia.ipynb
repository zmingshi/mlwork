{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "\n",
    "def not_empty(str):\n",
    "    return str and str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_main = 'http://bj.lianjia.com'\n",
    "\n",
    "f = open(u'北京二手房.csv', 'wb')\n",
    "f.write(unicode('\\xEF\\xBB\\xBF', 'utf-8'))  # 文件头\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['区域', '小区名称', '户型', '面积', '价格(万)', '单价(元/平米)',\n",
    "                 '性质', '朝向', '装修', '是否有电梯', '楼层', '建筑年代', '楼型'])\n",
    "res = requests.get('http://bj.lianjia.com/ershoufang')\n",
    "res = res.text.encode(res.encoding).decode('utf-8')\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "# print soup.prettify()\n",
    "districts = soup.find(name='div', attrs={'data-role': 'ershoufang'})  # <div data-role=\"ershoufang\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dfbbd5a7c286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# soup.select()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdistrict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistricts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdistrict_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m  \u001b[0;31m# '东城', '西城', '朝阳', '海淀'......\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistrict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# soup.select()\n",
    "for district in districts.find_all(name='a'):\n",
    "    print district['title']\n",
    "    district_name = district.text  # '东城', '西城', '朝阳', '海淀'......\n",
    "    url = '%s%s' % (url_main, district['href'])\n",
    "    # print url\n",
    "    res = requests.get(url)\n",
    "    res = res.text.encode(res.encoding).decode('utf-8')\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "    # print soup.prettify()\n",
    "    page = soup.find('div', {'class': 'page-box house-lst-page-box'})\n",
    "    if not page:  # 平谷区没有房源，直接返回\n",
    "        continue\n",
    "    total_pages = dict(eval(page['page-data']))['totalPage']  # 总页数\n",
    "    # print total_pages\n",
    "    for j in range(1, total_pages + 1):\n",
    "        url_page = '%spg%d/' % (url, j)\n",
    "        res = requests.get(url_page)\n",
    "        res = res.text.encode(res.encoding).decode('utf-8')\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "        # print soup.prettify()\n",
    "        sells = soup.find(name='ul', attrs={'class': 'sellListContent', 'log-mod': 'list'})\n",
    "        if not sells:\n",
    "            continue\n",
    "        # <a class=\"title\" data-bl=\"list\" data-el=\"ershoufang\" data-log_index=\"1\" href=\"XX\" target=\"_blank\">\n",
    "        titles = soup.find_all(name='a', attrs={'class': 'title', 'data-bl': 'list', 'data-el': 'ershoufang'})\n",
    "        # <a data-el=\"region\" data-log_index=\"1\" href=\"X\" target=\"_blank\">\n",
    "        regions = sells.find_all(name='a', attrs={'data-el': 'region'})\n",
    "        infos = sells.find_all(name='div', class_='houseInfo')  # <div class=\"houseInfo\">\n",
    "        infos2 = sells.find_all(name='div', class_='positionInfo')  # <div class=\"positionInfo\">\n",
    "        prices = sells.find_all(name='div', class_='totalPrice')  # <div class=\"totalPrice\">\n",
    "        unit_prices = sells.find_all(name='div',\n",
    "                                     class_='unitPrice')  # <div class=\"unitPrice\" data-hid=\"X\" data-price=\"X\" data-rid=\"X\">\n",
    "        subways = sells.find_all(name='span', class_='subway')  # <span class=\"subway\">\n",
    "        taxs = sells.find_all(name='span', class_='taxfree')  # <span class=\"taxfree\">\n",
    "        N = max(len(titles), len(regions), len(prices), len(unit_prices), len(subways), len(taxs), len(infos),\n",
    "                len(infos2))\n",
    "        # for title, region, price, unit_price, subway, tax, info, info2 in zip(titles, regions, prices, unit_prices, subways, taxs, infos, infos2):\n",
    "        for i in range(N):\n",
    "            room_type = area = orientation = decoration = elevator = floor = year = slab_tower = None\n",
    "            title = titles[i] if len(titles) > i else None\n",
    "            region = regions[i] if len(regions) > i else None\n",
    "            price = prices[i] if len(prices) > i else None\n",
    "            unit_price = unit_prices[i] if len(unit_prices) > i else None\n",
    "            subway = subways[i] if len(subways) > i else None\n",
    "            tax = taxs[i] if len(taxs) > i else None\n",
    "            info = infos[i] if len(infos) > i else None\n",
    "            info2 = infos2[i] if len(infos2) > i else None\n",
    "            if title:\n",
    "                print 'Title: ', title.text\n",
    "            if region:\n",
    "                region = region.text\n",
    "            if price:\n",
    "                price = price.text\n",
    "                price = price[:price.find('万')]\n",
    "            if unit_price:\n",
    "                unit_price = unit_price.span.text.strip()\n",
    "                unit_price = unit_price[:unit_price.find('元/平米')]\n",
    "                if unit_price.find('单价') != -1:\n",
    "                    unit_price = unit_price[2:]\n",
    "            if subway:\n",
    "                subway = subway.text.strip()\n",
    "            if tax:\n",
    "                tax = tax.text.strip()\n",
    "            if info:\n",
    "                info = info.text.split('|')\n",
    "                room_type = info[1].strip()  # 几室几厅\n",
    "                area = info[2].strip()  # 房屋面积\n",
    "                area = area[:area.find('平米')]\n",
    "                orientation = info[3].strip().replace(' ', '')  # 朝向\n",
    "                decoration = '-'\n",
    "                if len(info) > 4:  # 如果是车位，则该项为空\n",
    "                    decoration = info[4].strip()  # 装修类型：简装、中装、精装、豪装、其他\n",
    "                elevator = '无'\n",
    "                if len(info) > 5:\n",
    "                    elevator = info[5].strip()  # 是否有电梯：有、无\n",
    "            if info2:\n",
    "                info2 = filter(not_empty, info2.text.split(' '))\n",
    "                floor = info2[0].strip()\n",
    "                info2 = info2[1]\n",
    "                year = info2[:info2.find('年')]\n",
    "                slab_tower = info2[info2.find('建') + 1:]\n",
    "            print district_name, region, room_type, area, price, unit_price, tax, orientation, decoration, elevator, floor, year, slab_tower\n",
    "            writer.writerow(\n",
    "                [district_name, region, room_type, area, price, unit_price, tax, orientation, decoration, elevator,\n",
    "                 floor, year, slab_tower])\n",
    "            # break\n",
    "            # break\n",
    "            # break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
